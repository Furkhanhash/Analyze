import csv
import mmap
import tqdm as tqdm
import requests
from bs4 import BeautifulSoup
import re
import urllib.parse as urlparse
from urllib.parse import parse_qs
import base64
import sys

# implemented progress bar in this


def get_num_lines(file1_path):
    fp = open(file1_path, "r+")
    buf = mmap.mmap(fp.fileno(), 0)
    lines = 0
    while buf.readline():
        lines += 1
    return lines

def policy_check(soup):
    # we check this function only when malware data is not available if it is not malware then it might be violation.
    #soup = BeautifulSoup(table, 'html.parser')
    td= soup.find('td')
    td1 = td.text.replace('&lt;\/td&gt;','')
    # take the first elemet form list
    td2 = td1.split('<\/td><\/tr>')[0]
    #again splitting to td2 to get the desired output
    td3 = td2.split('<\/td>')
    #print(td3)
    policy = td3[0]
    #remove escpe sequence and " using replace keyword from list elemets
    criteria = td3[1].replace('\\','')
    detected = td3[2].replace('"','').replace('\\','')
    malware_domain,malware_type = "NULL","NULL"
    type = "VIOLATION"
    return (policy,criteria,detected,malware_domain,malware_type,type)

def parse_url(input):
    url_parsed = urlparse.urlparse(input)
    adServerId=parse_qs(url_parsed.query)['adServerId'][0]
    if adServerId == '243':
        ucrid=parse_qs(url_parsed.query)['ucrid'][0]
        error = "NULL"
        return adServerId,ucrid,error
    else :
        #we check the ucrid only for adServerId=243 other adServerId are for passbacks and for other adnetwork
        ucrid="NULL"
        error = "adServerId_"+adServerId+"_ucrid_NULL"
        return adServerId,ucrid,error

def call_chain(display_csid,tsid):

    #check for aktrack,clicktrack and lyr call if this call not available then provides NULL in output
    site3 = 'https://www.themediatrust.com/process_action.php?process_action=creative_qa/cqa_scan_details_tabs-v7&qgs=1&v=7&activeTab=call_chain&csid=' + display_csid + '&tsid=' + tsid
    # print(site3)
    r3 = requests.get(site3)
    soup3 = BeautifulSoup(r3.content, 'html.parser')

    aktrack = soup3.find('a', href=re.compile(r'[/](aktrack.pubmatic.com)[/]'))

    if aktrack is None:
        clicktrack = soup3.find('a', href=re.compile(r'[/](clicktrack.pubmatic.com)[/]'))

    if aktrack is None and clicktrack is None:
        lyr = soup3.find('a', href=re.compile(r'[/](lyr.pubmatic.com)[/]'))
        #print(lyr)

    if aktrack is not None:
        aktrack_call = aktrack.attrs['href']
        adServerId, ucrid, error = parse_url(aktrack_call)
        return (adServerId, ucrid, error)
    elif clicktrack is not None:
        clicktrack_call = clicktrack.attrs['href']
        clicktrack_parsed = urlparse.urlparse(clicktrack_call)
        #print(clicktrack_call)
        raw_clickdata = parse_qs(clicktrack_parsed.query)['clickData'][0]
        clickdata = raw_clickdata.split('==')[0]
        clickdata_decode = base64.b64decode(clickdata + '===')
        clicktrack_decoded = 'https://clicktrack.pubmatic.com/AdServer/AdDisplayTrackerServlet?' + str(clickdata_decode[1:])
        adServerId, ucrid, error = parse_url(clicktrack_decoded)
        return(adServerId, ucrid, error)

    elif lyr is not None:
        lyr_call = lyr.attrs['href']
        url_parsed = urlparse.urlparse(lyr_call)
        parse_dict= parse_qs(url_parsed.query)
        #print(parse_dict)
        if 'adServerId' in parse_dict :
            adServerId = parse_dict['adServerId']
        else:
            adServerId = "NULL"

        if 'ucrid' in parse_dict:
            ucrid = parse_dict['ucrid'][0]
            error = "NULL"
        else :
            ucrid = "NULL"
            error = "ucrid is not availble in lyr call"
        return(adServerId,ucrid,error)
    else:
        adServerId = "NULL"
        ucrid = "NULL"
        error = "aktrack, clicktrack, lyr call not found"
        return (adServerId, ucrid, error)


def main():
    with open(file1_path, 'r') as file1:
        for line in tqdm.tqdm(file1, total=get_num_lines(file1_path)):
            tsid=line.strip()
            #print(tsid)

            site1 = 'https://www.themediatrust.com/process_action.php?qgs=1&v=7&tsid='+tsid+'&auth=&process_action=deck/public_deck_json-v7'

            #print(site1)

            r1 = requests.get(site1)
            soup1 = BeautifulSoup(r1.content, 'html.parser')
            #print(soup1)

            display_csid_test = soup1.find('input', {'id': 'display_csid'})

            #check url is accessbile or not using display_csid_test
            if display_csid_test is not None:
                display_csid = soup1.find('input', {'id': 'display_csid'})['value']
                display_sid = soup1.find('input',{'id':'display_sid'})['value']
                site2 = 'https://www.themediatrust.com/process_action.php?process_action=creative_qa/cqa_scan_details_tabs-v7&qgs=1&v=7&activeTab=malware&csid='+display_csid+'&tsid='+tsid
                #print(site2)
                r2 = requests.get(site2)
                soup2 = BeautifulSoup(r2.content, 'html.parser')

                span_details = soup2.find_all('div',{'title': re.compile('^[a-zA-Z0-9]*')})
                #print(span_details)

                if not span_details:
                    policy, criteria, detected,malware_domain,malware_type,type = policy_check(soup1)
                    adServerId, ucrid, error = call_chain(display_csid, tsid)
                    #print(tsid+"\t"+type+"\t"+malware_type+"\t"+malware_domain+"\t"+policy+"\t"+detected+"\t"+adServerId+"\t"+ucrid+"\t"+error)

                else:
                    adServerId, ucrid, error = call_chain(display_csid, tsid)
                    for item in span_details:
                            malware_domain=item.get("title")
                            malware_type=item.find("b").text
                            policy, criteria, detected = "NULL","NULL","NULL"
                            type ="MALWARE"
                            ##print(tsid + "\t" + type + "\t" + malware_type + "\t" + malware_domain +"\t" + policy+"\t"+ detected +"\t" + adServerId + "\t" + ucrid + "\t" + error)
                            file2.writerow([tsid, type, malware_type, malware_domain, policy, detected, adServerId, ucrid, error])
            else:
              display_csid,display_sid,malware_type,malware_domain =  "NULL","NULL","NULL","NULL"
              type="NOT_SURE"
              policy,detected,adServerId,ucrid = "NULL","NULL","NULL","NULL"
              error = "tsid_not_found_URL_UNACCESSABLE"
              #print(tsid + "\t" + type + "\t" + malware_type + "\t" + malware_domain + "\t" + policy + "\t" + detected + "\t" + adServerId + "\t" + ucrid + "\t" + error)
              file2.writerow([tsid, type, malware_type, malware_domain, policy, detected, adServerId, ucrid, error])
            #print('________________________________________________')

        file1.close()

if __name__ == '__main__':
    filename=sys.argv[1]
    print("fuck")
    file1_path = filename
    file2 = csv.writer(open("output/"+filename, "w+"))
    file2.writerow(["tsid ", "type ", "malware_type ", "malware_domain", "policy", "detected", "adServerId ", "ucrid ", "error"])
    main()